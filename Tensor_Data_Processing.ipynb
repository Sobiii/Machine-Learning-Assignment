{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sobiii/Machine-Learning-Assignment/blob/main/Tensor_Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnIXFT3hbQhz",
        "outputId": "95e208d8-734e-4a15-da34-e8e0acc21d05"
      },
      "source": [
        "# Setting up google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "u528q8RCbQh6"
      },
      "source": [
        "# Data Manipulation\n",
        "\n",
        "* Basic data structure used in Deep Learning is the $n$-dimensional array, which is also called the *tensor*.\n",
        "* *Tensor class* is called `Tensor` in PyTorch and is similar to NumPy's `ndarray` with a few killer features.\n",
        "    * First, GPU is well-supported to accelerate the computation\n",
        "    * Second, the tensor class supports automatic differentiation.\n",
        "* These properties make the tensor class suitable for Deep Learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "scrolled": true,
        "tab": [
          "pytorch"
        ],
        "id": "LKSF3PUXbQh7"
      },
      "source": [
        "# To start, we import `torch`. Note that it's called PyTorch, we should import `torch` instead of `pytorch`.\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dRE9OyLbQh8",
        "outputId": "57883564-8e3b-4080-b941-d3e8853a0548"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 7,
        "id": "rGvyZmEwbQh9"
      },
      "source": [
        "# Tensor\n",
        "\n",
        "* A tensor represents a (possibly multi-dimensional) array of numerical values.\n",
        "    * A 1D tensor corresponds (in math) to a *vector*.\n",
        "    * A 2D tensor corresponds to a *matrix*.\n",
        "    * Tensors with more than two axes do not have special mathematical names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy1peA3MbQh9"
      },
      "source": [
        "# Vector\n",
        "\n",
        "* In math notation, we will usually denote vectors as bold-faced, lower-cased letters (e.g., $\\mathbf{x}$, $\\mathbf{y}$, and $\\mathbf{z})$.\n",
        "* Column vectors is the default orientation of vectors. In math, a column vector $\\mathbf{x}$ can be written as\n",
        "\n",
        "$$\\mathbf{x} =\\begin{bmatrix}x_{1}  \\\\x_{2}  \\\\ \\vdots  \\\\x_{n}\\end{bmatrix},$$\n",
        "where $x_1, \\ldots, x_n$ are elements of the vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxAdxaKcbQh9",
        "outputId": "6869a366-60cb-4a3b-a3e7-a206bd59c674"
      },
      "source": [
        "# A vector with 4 elements in the range 0-3\n",
        "# Unless otherwise specified, a new tensor is stored in main memory and designated for CPU-based computation\n",
        "x = torch.arange(4)\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeQa40RabQh-",
        "outputId": "cc8fe2ea-0f00-4b23-a9e5-3147db0289b6"
      },
      "source": [
        "# access the i-th element: x[i]\n",
        "print(x[3])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 11,
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI2FuIqebQh-",
        "outputId": "2f640858-0920-426b-c210-964820a14f89"
      },
      "source": [
        "# Vector shape i.e. dimensionality \n",
        "print(len(x), x.size(), x.shape, type(x.size()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 torch.Size([4]) torch.Size([4]) <class 'torch.Size'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUb8DVCUbQh_"
      },
      "source": [
        "# Matrices\n",
        "\n",
        "* Matrices (i.e. 2D tensors) will be typically denoted with bold-faced, capital letters (e.g., $\\mathbf{X}$, $\\mathbf{Y}$, and $\\mathbf{Z}$).\n",
        "\n",
        "* In math notation, we use $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ to express that the matrix $\\mathbf{A}$ consists of $m$ rows and $n$ columns of real-valued scalars.\n",
        "\n",
        "* Visually, we can illustrate any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ as a table,\n",
        "where each element $a_{ij}$ belongs to the $i^{\\mathrm{th}}$ row and $j^{\\mathrm{th}}$ column:\n",
        "\n",
        "$$\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}.$$\n",
        "\n",
        "* For any $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, the shape of $\\mathbf{A}$ is ($m$, $n$) or $m \\times n$.\n",
        "    * When a matrix has the same number of rows and columns, it is called a *square matrix*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9keq5sbQh_",
        "outputId": "3c4bb8ec-c326-4426-c94d-ae97f5a35c79"
      },
      "source": [
        "# Reshape function: change the shape of a tensor without changing the number of elements or their values \n",
        "A = torch.arange(20).reshape(5, 4)\n",
        "A, A[2, 3], A[2][3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11],\n",
              "         [12, 13, 14, 15],\n",
              "         [16, 17, 18, 19]]), tensor(11), tensor(11))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RINX4IB4vY-Y",
        "outputId": "5ef9aa4c-448d-4f47-e7a4-a1e47b47ade3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A[2, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv8Y_H1Qve36",
        "outputId": "0f378989-8715-415a-834c-e6c80167e0a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A[2][1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUOBVeOmxjea",
        "outputId": "c740a01c-afea-4104-8ef4-116783cd6efd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A[3][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTHcZn48xsg9",
        "outputId": "12dbedc6-7b27-4dc6-cc5c-bb333b94a628"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMIwWi0ZbQh_",
        "outputId": "d2d0d050-51ea-4d30-f14e-5a754e7bd9fd"
      },
      "source": [
        "# Matrix shape\n",
        "print(len(A), A.size(), A.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 torch.Size([5, 4]) torch.Size([5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxXo4Nm4yKDM",
        "outputId": "e9c174c8-120e-4b55-8da6-50a69f04da10"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65w-7Q1syJ1z",
        "outputId": "e6386a01-a014-4f53-e37f-dbdda44f83e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oY73MdHyJir",
        "outputId": "b1ce910c-1ca9-4ee1-fb43-4b11da6def89"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfnqT2DJbQiA",
        "outputId": "605e1b34-42ab-41d4-c142-6de77dabfe27"
      },
      "source": [
        "# use -1 for the dimension that can be automatically inferred\n",
        "A1 = torch.arange(20).reshape(5, -1);\n",
        "A2 = torch.arange(20).reshape(-1, 4);\n",
        "A==A1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Personal notes on inferring demensions:\n",
        "\n",
        "In the context of tensors, using -1 for a dimension means that the size of that dimension should be inferred automatically based on the sizes of the other dimensions and the total size of the data. This can be useful when working with tensors of varying sizes, as it allows the tensor operations to be performed without the need to manually specify the size of every dimension."
      ],
      "metadata": {
        "id": "T566I1OvzPTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-xiMhWpznI1",
        "outputId": "cd1e14d0-0ba6-4003-cbff-7f43d64497a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiyRa8wozt_7",
        "outputId": "ef7e8f43-da0f-4f7e-a371-0795e2dcf13c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq8STO4VbQiA",
        "outputId": "48a4ccd0-efb9-4a4b-d5db-09eb2f0926c2"
      },
      "source": [
        "# Transpose\n",
        "B = A.T\n",
        "B1 = A.transpose(1, 0)\n",
        "B, B1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  4,  8, 12, 16],\n",
              "         [ 1,  5,  9, 13, 17],\n",
              "         [ 2,  6, 10, 14, 18],\n",
              "         [ 3,  7, 11, 15, 19]]), tensor([[ 0,  4,  8, 12, 16],\n",
              "         [ 1,  5,  9, 13, 17],\n",
              "         [ 2,  6, 10, 14, 18],\n",
              "         [ 3,  7, 11, 15, 19]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agzHLi2Pz2ha",
        "outputId": "b46987bd-ab93-4eab-990f-b642c806c2d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8, 12, 16],\n",
              "        [ 1,  5,  9, 13, 17],\n",
              "        [ 2,  6, 10, 14, 18],\n",
              "        [ 3,  7, 11, 15, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHevmKK5z7Dj",
        "outputId": "e363930a-ac79-43bd-bc2c-0016e6651e86"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8, 12, 16],\n",
              "        [ 1,  5,  9, 13, 17],\n",
              "        [ 2,  6, 10, 14, 18],\n",
              "        [ 3,  7, 11, 15, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S2vzvhybQiB"
      },
      "source": [
        "# Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBVTYkptbQiB",
        "outputId": "999bb034-55be-483e-bfb3-5443fe1cdae7"
      },
      "source": [
        "# A 3D tensor\n",
        "X = torch.arange(24).reshape(2, 3, -1)\n",
        "X"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Personal notes on the explanation of the above code:\n",
        "\n",
        "The code is creating a 3D tensor X using the PyTorch library. The torch.arange(24) function creates a 1D tensor with a range of values from 0 to 23. The reshape(2, 3, -1) function is then used to reshape the 1D tensor into a 3D tensor with dimensions 2x3x4.\n",
        "\n",
        "The first argument 2 represents the number of elements in the first dimension, the second argument 3 represent the number of elements in the second dimension, and the third argument -1 represents the size of the third dimension. The value of -1 is used here to automatically infer the size of the third dimension based on the size of the data and the size of the first two dimensions.\n",
        "\n",
        "So the tensor X will have 2 matrices of size 3x4.\n",
        "\n",
        "It can also be understood as :\n",
        "X[0] = [[0,1,2,3],\n",
        "[4,5,6,7],\n",
        "[8,9,10,11]]\n",
        "\n",
        "X[1] = [[12,13,14,15],\n",
        "[16,17,18,19],\n",
        "[20,21,22,23]]\n",
        "\n",
        "It's a way of creating a tensor with a specific shape and values at the same time.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1GyHGPKN1ZJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimental code used for my understanding\n",
        "Y = torch.arange(30).reshape(3, 1, -1)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVP7R7wi1mA5",
        "outputId": "5f0512d3-5ad9-4cf8-d3a6-fcc9c829f1b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
              "\n",
              "        [[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
              "\n",
              "        [[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGz3gmpXbQiB"
      },
      "source": [
        "# Commonly-used Tensor Constuctors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dhFpD5sbQiB",
        "outputId": "e9e82f6b-839e-4759-eace-afeedb89e8be"
      },
      "source": [
        "# To fill a tensor with 1s\n",
        "torch.ones((2, 3, 4)) # with Ones"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEi7T-_qbQiC",
        "outputId": "2864536a-4075-4f02-f2e6-df0192e6d5ef"
      },
      "source": [
        "# To fill a tensor with 0s\n",
        "torch.zeros(2, 3) # with Zeros"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tof2tVtGbQiC",
        "outputId": "c518c5b4-5e90-40ba-c89e-6036aac12d04"
      },
      "source": [
        "# Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1\n",
        "torch.randn(3, 4) # samples from a Gaussian distribution with mean 0 and std of 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1048, -0.4926, -0.5236, -0.9925],\n",
              "        [ 0.9997, -0.3656, -1.4240,  0.1609],\n",
              "        [ 0.7900, -0.9788,  2.1395,  0.9936]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Personal Notes:\n",
        "\n",
        "It's important to note that the torch.randn() function generates random numbers each time it is called, so the output will be different every time the function is run.\n",
        "\n",
        "This function is commonly used in deep learning to initialize the weights of a model, with the hope that the random initialization will break any symmetry in the model, and therefore make the model more expressive."
      ],
      "metadata": {
        "id": "FgRQjVR83med"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUy5p6A6bQiC",
        "outputId": "6f6b26c4-18ec-4b21-8fdc-ab0366795c74"
      },
      "source": [
        "# Creates rensors from python lists\n",
        "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4]]) # From Python lists "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZreKf2bQiD"
      },
      "source": [
        "# Common Tensor Operators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp_a4tGObQiD",
        "outputId": "67845a13-004c-4caa-d52f-67011ea84c35"
      },
      "source": [
        "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "B = A.clone()  # Assign a copy of `A` to `B` by allocating new memory\n",
        "A, A + B, A * B, A + 2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  2.,  4.,  6.],\n",
              "         [ 8., 10., 12., 14.],\n",
              "         [16., 18., 20., 22.],\n",
              "         [24., 26., 28., 30.],\n",
              "         [32., 34., 36., 38.]]), tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]), tensor([[ 2.,  3.,  4.,  5.],\n",
              "         [ 6.,  7.,  8.,  9.],\n",
              "         [10., 11., 12., 13.],\n",
              "         [14., 15., 16., 17.],\n",
              "         [18., 19., 20., 21.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_8TN5WKbQiD",
        "outputId": "27026c09-a829-4d78-e410-58251280ab67"
      },
      "source": [
        "# Summations (same applies for mean() function)\n",
        "A.sum(), A.sum(dim=0), A.sum(dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(190.), tensor([40., 45., 50., 55.]), tensor([ 6., 22., 38., 54., 70.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9aakDknbQiE",
        "outputId": "0330bcdb-a5f0-4c83-c2d7-a1c32ef6b2cb"
      },
      "source": [
        "# Functions are applied element-wise\n",
        "torch.exp(A), A**2, torch.pow(A, 2), torch.cos(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01],\n",
              "         [5.4598e+01, 1.4841e+02, 4.0343e+02, 1.0966e+03],\n",
              "         [2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04],\n",
              "         [1.6275e+05, 4.4241e+05, 1.2026e+06, 3.2690e+06],\n",
              "         [8.8861e+06, 2.4155e+07, 6.5660e+07, 1.7848e+08]]),\n",
              " tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]),\n",
              " tensor([[  0.,   1.,   4.,   9.],\n",
              "         [ 16.,  25.,  36.,  49.],\n",
              "         [ 64.,  81., 100., 121.],\n",
              "         [144., 169., 196., 225.],\n",
              "         [256., 289., 324., 361.]]),\n",
              " tensor([[ 1.0000,  0.5403, -0.4161, -0.9900],\n",
              "         [-0.6536,  0.2837,  0.9602,  0.7539],\n",
              "         [-0.1455, -0.9111, -0.8391,  0.0044],\n",
              "         [ 0.8439,  0.9074,  0.1367, -0.7597],\n",
              "         [-0.9577, -0.2752,  0.6603,  0.9887]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFwrFy6YbQiE",
        "outputId": "b73d5b44-d491-4776-fa40-64cc1d763cb1"
      },
      "source": [
        "# Concatenation\n",
        "torch.cat((A, B), dim=0), torch.cat((A, B), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.],\n",
              "         [ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.,  8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15., 12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19., 16., 17., 18., 19.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQvDz7TqbQiE"
      },
      "source": [
        "# Dot Products\n",
        "\n",
        "* One of the most fundamental operations. \n",
        "* Given two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$, their *dot product* $\\mathbf{x}^\\top \\mathbf{y}$ (or $\\langle \\mathbf{x}, \\mathbf{y}  \\rangle$) is a sum over the products of the elements at the same position: $\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VMPW6RmbQiE",
        "outputId": "7a392b67-dbae-4e50-a36c-3507646c8609"
      },
      "source": [
        "x = torch.arange(4, dtype=torch.float32)\n",
        "y = torch.ones(4, dtype = torch.float32)\n",
        "x, y, torch.dot(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlrjbcofbQiF"
      },
      "source": [
        "* Dot products are useful in a wide range of contexts:\n",
        "    1. Given features stored in vector $\\mathbf{x}  \\in \\mathbb{R}^d$ and model weights in vector $\\mathbf{w} \\in \\mathbb{R}^d$, the *score* between features and model weights are given by $\\mathbf{x}^\\top \\mathbf{w}$.\n",
        "    2. When the weights are non-negative and sum to one (i.e., $\\left(\\sum_{i=1}^{d} {w_i} = 1\\right)$), the dot product expresses a *weighted average*.\n",
        "    3. After normalizing two vectors to have the unit length (to be defined below), the dot products express the cosine of the angle between them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWkx1OVQbQiF"
      },
      "source": [
        "# Matrix-Vector Products\n",
        "\n",
        "* Recall $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{x} \\in \\mathbb{R}^n$. Let us write $\\mathbf{A}$ in terms of its row vectors:\n",
        "$$\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_m \\\\\n",
        "\\end{bmatrix},$$\n",
        "where each $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^n$ is a row vector representing the $i^\\mathrm{th}$ row of the matrix $\\mathbf{A}$.\n",
        "\n",
        "* $\\mathbf{A}\\mathbf{x}$ is a column vector of length $m$, whose $i^\\mathrm{th}$ element is $\\mathbf{a}^\\top_i \\mathbf{x}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{A}\\mathbf{x}\n",
        "= \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_m \\\\\n",
        "\\end{bmatrix}\\mathbf{x}\n",
        "= \\begin{bmatrix}\n",
        " \\mathbf{a}^\\top_{1} \\mathbf{x}  \\\\\n",
        " \\mathbf{a}^\\top_{2} \\mathbf{x} \\\\\n",
        "\\vdots\\\\\n",
        " \\mathbf{a}^\\top_{m} \\mathbf{x}\\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "* Multiplication by $\\mathbf{A}\\in \\mathbb{R}^{m \\times n}$ projects vectors from $\\mathbb{R}^{n}$ to $\\mathbb{R}^{m}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlHXImeIbQiF",
        "outputId": "d88cd6cc-a8f2-44e1-8f72-bec8a287eb06"
      },
      "source": [
        "A.shape, x.shape, torch.mv(A, x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4WilX3FbQiF"
      },
      "source": [
        "# Matrix-Matrix Multiplication\n",
        "\n",
        "\n",
        "* Asssume that we have two matrices $\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:\n",
        "\n",
        "$$\\mathbf{A}=\\begin{bmatrix}\n",
        " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
        " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
        "\\end{bmatrix},\\quad\n",
        "\\mathbf{B}=\\begin{bmatrix}\n",
        " b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n",
        " b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n",
        "\\end{bmatrix}.$$\n",
        "\n",
        "\n",
        "* Denote by $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^k$ the row vector representing the $i^\\mathrm{th}$ row of $\\mathbf{A}$, and by $\\mathbf{b}_{j} \\in \\mathbb{R}^k$ the column vector from the $j^\\mathrm{th}$ column of $\\mathbf{B}$. We write $\\mathbf{A}$ and $\\mathbf{B}$ as:\n",
        "\n",
        "$$\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix},\n",
        "\\quad \\mathbf{B}=\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "* Then the matrix product $\\mathbf{C} \\in \\mathbb{R}^{n \\times m}$ is:\n",
        "\n",
        "$$\\mathbf{C} = \\mathbf{AB} = \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}\n",
        "= \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\mathbf{b}_1 & \\mathbf{a}^\\top_{1}\\mathbf{b}_2& \\cdots & \\mathbf{a}^\\top_{1} \\mathbf{b}_m \\\\\n",
        " \\mathbf{a}^\\top_{2}\\mathbf{b}_1 & \\mathbf{a}^\\top_{2} \\mathbf{b}_2 & \\cdots & \\mathbf{a}^\\top_{2} \\mathbf{b}_m \\\\\n",
        " \\vdots & \\vdots & \\ddots &\\vdots\\\\\n",
        "\\mathbf{a}^\\top_{n} \\mathbf{b}_1 & \\mathbf{a}^\\top_{n}\\mathbf{b}_2& \\cdots& \\mathbf{a}^\\top_{n} \\mathbf{b}_m\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yft9jH64bQiG",
        "outputId": "22592069-2dfb-4403-e6b2-d36711f57c51"
      },
      "source": [
        "# Matrix multiplication\n",
        "B = torch.ones(4, 3)\n",
        "A, B, torch.mm(A, B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]), tensor([[ 6.,  6.,  6.],\n",
              "         [22., 22., 22.],\n",
              "         [38., 38., 38.],\n",
              "         [54., 54., 54.],\n",
              "         [70., 70., 70.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ewx1oBbQiH"
      },
      "source": [
        "# Norms\n",
        "\n",
        "* Some of the most useful operators in linear algebra are *norms*.\n",
        "* Informally, the norm of a vector tells us how *big* a vector is (0 is the minimum). \n",
        "* A (vector) norm is a function $f$ that maps a vector to a scalar, satisfying the following properties:\n",
        "    1. $f(\\alpha \\mathbf{x}) = |\\alpha| f(\\mathbf{x}).$\n",
        "\n",
        "    2. $f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y}).$\n",
        "\n",
        "    3. $f(\\mathbf{x}) \\geq 0.$\n",
        "\n",
        "    4. $\\forall i, x_i = 0 \\Leftrightarrow f(\\mathbf{x})=0.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvYSJkRbQiH"
      },
      "source": [
        "* The $L_2$ *norm* of $\\mathbf{x}$ is the square root of the sum of the squares of the vector elements:\n",
        "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2},$$\n",
        "where the subscript $2$ is often omitted in $L_2$ norms, i.e., $\\|\\mathbf{x}\\|$ is equivalent to $\\|\\mathbf{x}\\|_2$. \n",
        "\n",
        "* The $L_1$ *norm* is expressed as the sum of the absolute values of the vector elements:\n",
        "\n",
        "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|.$$\n",
        "\n",
        "* In Deep Learning, we are often trying to solve optimization problems: e.g. *minimize* the distance between the model's predictions and the ground-truth observations.\n",
        "    * The optimization obectives are ofter expressed as norms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 53,
        "id": "AUfy0xr5bQiH"
      },
      "source": [
        "# Broadcasting Mechanism\n",
        "\n",
        "* In maths, in order to to perform elementwise operations between two tensors, they need to have the same shape. \n",
        "* In Python and PyTorch, under certain conditions, even when their shapes differ, we can still perform elementwise operations by invoking the *broadcasting mechanism*.\n",
        "* This mechanism works in the following way: \n",
        "    * First, expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape.\n",
        "    * Second, carry out the elementwise operations on the resulting arrays.\n",
        "\n",
        "* In most cases, we broadcast along a dimension where an array initially only has length 1, such as in the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 55,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5nPGrnbQiH",
        "outputId": "d70c3915-e3d1-466f-86e9-570899559581"
      },
      "source": [
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "a, b, a.size(), b.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]), tensor([[0, 1]]), torch.Size([3, 1]), torch.Size([1, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 58,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF3rrJd9bQiI",
        "outputId": "6f9c68c3-02e3-4b30-8d8a-ef0ad3479bcb"
      },
      "source": [
        "a + b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67G-yuhxbQiI"
      },
      "source": [
        "# Another example with sums\n",
        "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoWThrfpbQiJ",
        "outputId": "74329979-3603-41af-dc99-2700f1632cf4"
      },
      "source": [
        "B1 = A.sum(dim=1);\n",
        "B2 = A.sum(dim=1, keepdims=True);\n",
        "B1, B2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 6., 22., 38., 54., 70.]), tensor([[ 6.],\n",
              "         [22.],\n",
              "         [38.],\n",
              "         [54.],\n",
              "         [70.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf77hLrpbQiJ",
        "outputId": "34c2da53-e7ec-4efa-a536-f09abe94cf65"
      },
      "source": [
        "# Dimensionality\n",
        "B1.size(), B2.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5]), torch.Size([5, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BobOi9e3bQiK",
        "outputId": "d04a1865-0f75-4baf-fc03-920bb0352b69"
      },
      "source": [
        "A/B2 # A/B1 won't work"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 59,
        "id": "KFP1LNMDbQiK"
      },
      "source": [
        "# Tensor Indexing and Slicing\n",
        "\n",
        "* Just as in any other Python array, elements in a tensor can be accessed by index.\n",
        "    * The first element has index 0 and ranges are specified to include the first but *before* the last element.\n",
        "    * As in standard Python lists, we can access elements according to their relative position to the end of the list by using negative indices.\n",
        "    * Example: `[-1]` selects the last element and `[1:3]` selects the second and the third elements as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 60,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvD7dGIrbQiL",
        "outputId": "fab1c1d7-14b0-4c48-d8f8-70e00c06afee"
      },
      "source": [
        "X = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "X, X[1:3, :], X[1:3, :2],  X[-1, :], X[-2:-1, :] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]), tensor([[4., 5.],\n",
              "         [8., 9.]]), tensor([16., 17., 18., 19.]), tensor([[12., 13., 14., 15.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 68,
        "id": "G1ua9S-KbQiL"
      },
      "source": [
        "# Saving Memory\n",
        "\n",
        "* Running operations can cause new memory to be allocated to store the results.\n",
        "* We do not want to allocate memory unnecessarily all the time.\n",
        "    * In machine learning, we might have hundreds of megabytes of parameters\n",
        "* Where possible, we want to perform these updates *in place*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 69,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HAGjd9bQiL",
        "outputId": "2fa8888c-3312-4661-dc26-bd5cc9164b14"
      },
      "source": [
        "# In place example\n",
        "X = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "Y = 10*X\n",
        "print(id(X), id(Y))\n",
        "Y = Y + X # not in-place\n",
        "print(id(X), id(Y))\n",
        "Y += X # in-place\n",
        "print(id(X), id(Y))\n",
        "Y[:] = Y + X # in-place\n",
        "print(id(X), id(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140377999456584 140377999456512\n",
            "140377999456584 140377999432944\n",
            "140377999456584 140377999432944\n",
            "140377999456584 140377999432944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 80,
        "id": "IPZ7SUmybQiM"
      },
      "source": [
        "# Conversion to Other Python Objects\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 82,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGMYuFTsbQiM",
        "outputId": "f3d79b90-ac32-421b-8cb6-09372635b590"
      },
      "source": [
        "# Converting to a NumPy array, or vice versa\n",
        "A = X.numpy()\n",
        "B = torch.tensor(A)\n",
        "type(A), type(B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 86,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdBl_j_AbQiM",
        "outputId": "dca06836-afd2-4a07-a134-994767860aec"
      },
      "source": [
        "# Converting to a size-1 tensor to a Python scalar,\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xaA19TIxU8f"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}